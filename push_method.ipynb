{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Asynchronous Indexing Pipeline with Text and Image Embeddings  \n",
    "   \n",
    "This notebook demonstrates how to create a **custom asynchronous indexing pipeline** that:  \n",
    "   \n",
    "- Reads PDF documents from Azure Blob Storage.  \n",
    "- Extracts text and images using Azure Document Intelligence.  \n",
    "- Generates embeddings for text and images using **Cohere models** in **Azure AI Foundry**.  \n",
    "- Indexes the data into **Azure AI Search** with separate `text_vector` and `image_vector` fields.  \n",
    "- Allows searching over text and image vectors.  \n",
    "   \n",
    "We will go through the following steps:  \n",
    "   \n",
    "1. **Install Required Libraries**  \n",
    "2. **Set Up Environment Variables**  \n",
    "3. **Create the Azure AI Search Index**  \n",
    "4. **Define the Custom Indexing Pipeline Components**  \n",
    "5. **Initialize and Run the Indexing Pipeline**  \n",
    "6. **Perform Test Searches**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure logging \n",
    "To ensure a clear and structured output during the execution of this notebook, we configure logging at the start. This helps track the progress and debug any issues efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging for a clearer experience   \n",
    "import logging  \n",
    "   \n",
    "# Configure the root logger  \n",
    "logging.basicConfig(  \n",
    "    level=logging.INFO,  # Set root logger level  \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'  \n",
    ")  \n",
    "   \n",
    "# Suppress logs from azure and uamqp libraries  \n",
    "logging.getLogger('azure').setLevel(logging.WARNING)  \n",
    "logging.getLogger('uamqp').setLevel(logging.WARNING)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up Environment Variables  \n",
    "   \n",
    "Ensure that the `.env` file contains the following environment variables:  \n",
    "  \n",
    "- `AZURE_SEARCH_SERVICE_ENDPOINT`  \n",
    "- `AZURE_SEARCH_API_KEY`  \n",
    "- `AZURE_STORAGE_ACCOUNT_NAME`  \n",
    "- `AZURE_STORAGE_ACCOUNT_SUB_ID`  \n",
    "- `AZURE_STORAGE_ACCOUNT_RG_NAME`  \n",
    "- `AZURE_STORAGE_ACCOUNT_CONTAINER_NAME`  \n",
    "- `DOCUMENTINTELLIGENCE_ENDPOINT`  \n",
    "- `DOCUMENTINTELLIGENCE_API_KEY`  \n",
    "- `AZURE_AI_FOUNDRY_ENDPOINT`  \n",
    "- `AZURE_AI_FOUNDRY_KEY`  \n",
    "- `TEXT_EMBEDDING_MODEL` \n",
    "- `TEXT_EMBEDDING_DIMENSIONS` \n",
    "- `IMAGE_EMBEDDING_MODEL` \n",
    "- `IMAGE_EMBEDDING_DIMENSIONS` \n",
    "\n",
    "\n",
    "Avoid hardcoding sensitive information in the notebook. \n",
    "   \n",
    "Ensure that the identities used have the necessary permissions (e.g., **Storage Blob Data Reader** role).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "from dotenv import load_dotenv  \n",
    "   \n",
    "# Load environment variables from .env file  \n",
    "load_dotenv(override=True)  \n",
    "   \n",
    "# Azure AI Search settings  \n",
    "search_service_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]  \n",
    "search_api_key = os.environ[\"AZURE_SEARCH_API_KEY\"]  \n",
    "index_name = \"asynch-custom-push-products-demo\"  \n",
    "   \n",
    "# Azure Storage settings  \n",
    "storage_account_name = os.environ[\"AZURE_STORAGE_ACCOUNT_NAME\"]  \n",
    "storage_container_name = os.environ[\"AZURE_STORAGE_ACCOUNT_CONTAINER_NAME\"]  \n",
    "   \n",
    "# Azure AI Inference settings (for embeddings)  \n",
    "ai_foundry_endpoint = os.environ[\"AZURE_AI_FOUNDRY_ENDPOINT\"]  \n",
    "ai_foundry_key = os.environ[\"AZURE_AI_FOUNDRY_KEY\"] \n",
    "text_embedding_model = os.environ[\"TEXT_EMBEDDING_MODEL\"]\n",
    "text_embedding_dimensions = int(os.getenv(\"TEXT_EMBEDDING_DIMENSIONS\", 1024)) \n",
    "image_embedding_model= os.environ[\"IMAGE_EMBEDDING_MODEL\"]\n",
    "image_embedding_dimensions =  int(os.getenv(\"IMAGE_EMBEDDING_DIMENSIONS\", 1024))    # Set this based on your image embedding model  \n",
    "   \n",
    "# Azure Document Intelligence settings  \n",
    "document_intelligence_endpoint = os.environ[\"DOCUMENTINTELLIGENCE_ENDPOINT\"]  \n",
    "document_intelligence_key = os.environ[\"DOCUMENTINTELLIGENCE_API_KEY\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the Azure AI Search Index  \n",
    "   \n",
    "We'll create the search index with the appropriate schema, including separate fields for `text_vector` and `image_vector`, and a `page_number` field to track the pages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'asynch-custom-push-products-demo' created or updated.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchField, \n",
    "    SimpleField, \n",
    "    SearchFieldDataType,  \n",
    "    VectorSearch,  \n",
    "    HnswAlgorithmConfiguration,  \n",
    "    VectorSearchProfile,  \n",
    "    SemanticConfiguration,  \n",
    "    SemanticSearch,  \n",
    "    SemanticPrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchIndex  \n",
    ")  \n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "   \n",
    "# Create a SearchIndexClient  \n",
    "search_index_client = SearchIndexClient(  \n",
    "    endpoint=search_service_endpoint,  \n",
    "    credential=AzureKeyCredential(search_api_key)  \n",
    ")  \n",
    "   \n",
    "# Define the index schema  \n",
    "fields = [  \n",
    "    SearchField(  \n",
    "        name=\"parent_id\",  \n",
    "        type=SearchFieldDataType.String,  \n",
    "        filterable=True,  \n",
    "        facetable=True,  \n",
    "        sortable=True  \n",
    "    ),  \n",
    "    SearchField(  \n",
    "        name=\"chunk_id\",  \n",
    "        type=SearchFieldDataType.String,  \n",
    "        key=True,  \n",
    "        filterable=True,  \n",
    "        facetable=True,  \n",
    "        sortable=True  \n",
    "    ),  \n",
    "    SearchField(  \n",
    "        name=\"title\",  \n",
    "        type=SearchFieldDataType.String,  \n",
    "        filterable=True,  \n",
    "        facetable=True,  \n",
    "        sortable=True  \n",
    "    ),  \n",
    "    SearchField(  \n",
    "        name=\"chunk\",  \n",
    "        type=SearchFieldDataType.String,  \n",
    "        searchable=True  \n",
    "    ),  \n",
    "    SearchField(  \n",
    "        name=\"text_vector\",  \n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  \n",
    "        vector_search_dimensions=text_embedding_dimensions,  \n",
    "        vector_search_profile_name=\"textHnswProfile\",  \n",
    "    ),  \n",
    "    SearchField(  \n",
    "        name=\"image_vector\",  \n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  \n",
    "        vector_search_dimensions=image_embedding_dimensions,  \n",
    "        vector_search_profile_name=\"imageHnswProfile\",  \n",
    "    ),  \n",
    "    SearchField(  \n",
    "        name=\"page_number\",  \n",
    "        type=SearchFieldDataType.Int32,  \n",
    "        filterable=True,  \n",
    "        facetable=True,  \n",
    "        sortable=True  \n",
    "    ), \n",
    "        # Field for content format (text,image)\n",
    "    SimpleField(  \n",
    "        name=\"content_type\",  \n",
    "        type=\"Edm.String\",  \n",
    "        filterable=True,  \n",
    "        facetable=True,  \n",
    "        sortable=True  \n",
    "    ), \n",
    "    # Field to retrieve source document for citation \n",
    "    SimpleField(  \n",
    "        name=\"source_link\",  \n",
    "        type=\"Edm.String\",  \n",
    "        retrievable=True  \n",
    "    ),    \n",
    "]  \n",
    "   \n",
    "# Configure the vector search settings  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnswAlgorithm\")  \n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"textHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnswAlgorithm\",  \n",
    "        ),  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"imageHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnswAlgorithm\",  \n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "   \n",
    "# Configure semantic search settings (optional)  \n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(  \n",
    "        title_field=SemanticField(field_name=\"title\"),  \n",
    "        content_fields=[SemanticField(field_name=\"chunk\")],  \n",
    "    ),  \n",
    ")  \n",
    "   \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "   \n",
    "# Create the search index  \n",
    "index = SearchIndex(  \n",
    "    name=index_name,  \n",
    "    fields=fields,  \n",
    "    vector_search=vector_search,  \n",
    "    semantic_search=semantic_search,  \n",
    ")  \n",
    "   \n",
    "# Create or update the index in Azure Cognitive Search  \n",
    "search_index_client.create_or_update_index(index)  \n",
    "   \n",
    "print(f\"Index '{index.name}' created or updated.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Custom Indexing Pipeline Components  \n",
    "   \n",
    "The custom indexing pipeline consists of the following components:  \n",
    "   \n",
    "- **FileReader**: Reads PDFs using Azure Document Intelligence and extracts text and images.  \n",
    "- **Chunker**: Splits the text into chunks for embedding.  \n",
    "- **TextEmbedder**: Generates text embeddings using Azure OpenAI.  \n",
    "- **ImageEmbedder**: Generates image embeddings using Azure AI Inference.  \n",
    "- **FileUploader**: Uploads the processed documents into Azure Cognitive Search.  \n",
    "- **AsynchronousIndexer**: Orchestrates the entire pipeline asynchronously.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize and Run the Indexing Pipeline  \n",
    "   \n",
    "Now we'll initialize the `AsynchronousIndexer` with the appropriate settings and run the indexing pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 14:51:13,205 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_0: Reading document Chunky_Knit_Oversized_Sweater.pdf\n",
      "2025-01-09 14:51:13,221 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_1: Reading document Classic_Denim_Jacket.pdf\n",
      "2025-01-09 14:51:13,221 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_2: Reading document Relaxed_Fit Linen_Pants.pdf\n",
      "2025-01-09 14:51:16,871 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_2: Completed analyze_document for Relaxed_Fit Linen_Pants.pdf\n",
      "2025-01-09 14:51:17,056 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_0: Completed analyze_document for Chunky_Knit_Oversized_Sweater.pdf\n",
      "2025-01-09 14:51:17,071 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_1: Completed analyze_document for Classic_Denim_Jacket.pdf\n",
      "2025-01-09 14:51:18,121 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_1: Found 1 figures in Classic_Denim_Jacket.pdf\n",
      "2025-01-09 14:51:18,505 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_1: Finished reading Classic_Denim_Jacket.pdf in 5.28 seconds\n",
      "2025-01-09 14:51:18,505 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_1: Done processing Classic_Denim_Jacket.pdf\n",
      "2025-01-09 14:51:18,505 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_2: Found 1 figures in Relaxed_Fit Linen_Pants.pdf\n",
      "2025-01-09 14:51:18,722 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_2: Finished reading Relaxed_Fit Linen_Pants.pdf in 5.50 seconds\n",
      "2025-01-09 14:51:18,722 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_2: Done processing Relaxed_Fit Linen_Pants.pdf\n",
      "2025-01-09 14:51:18,722 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Chunking document Classic_Denim_Jacket.pdf page 1\n",
      "2025-01-09 14:51:18,722 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Finished chunking in 0.00 seconds\n",
      "2025-01-09 14:51:18,722 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Chunking document Classic_Denim_Jacket.pdf page 2\n",
      "2025-01-09 14:51:18,722 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Finished chunking in 0.00 seconds\n",
      "2025-01-09 14:51:18,722 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Chunking document Relaxed_Fit Linen_Pants.pdf page 1\n",
      "2025-01-09 14:51:18,722 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Finished chunking in 0.00 seconds\n",
      "2025-01-09 14:51:18,722 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Chunking document Relaxed_Fit Linen_Pants.pdf page 2\n",
      "2025-01-09 14:51:18,722 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Finished chunking in 0.00 seconds\n",
      "2025-01-09 14:51:18,722 - asynch_indexer.AsynchronousIndexer - INFO - ImageEmbedder image_embedder_0:Embedding image 7a413492-7220-4dbd-9dc1-c54fa080e0fe from document Classic_Denim_Jacket.pdf page 1\n",
      "2025-01-09 14:51:23,289 - asynch_indexer.AsynchronousIndexer - INFO - ImageEmbedder image_embedder_0: Successfully processed image 7a413492-7220-4dbd-9dc1-c54fa080e0fe using model embed-multilingual-v3.0-image. Token consumption {'prompt_tokens': 1000, 'completion_tokens': 0, 'total_tokens': 1000, 'images': 1}\n",
      "2025-01-09 14:51:23,289 - asynch_indexer.AsynchronousIndexer - INFO - ImageEmbedder image_embedder_0:Embedding image d77cfeef-9d20-4705-bdd1-cdea59f31060 from document Relaxed_Fit Linen_Pants.pdf page 1\n",
      "2025-01-09 14:51:24,737 - asynch_indexer.AsynchronousIndexer - INFO - ImageEmbedder image_embedder_0: Successfully processed image d77cfeef-9d20-4705-bdd1-cdea59f31060 using model embed-multilingual-v3.0-image. Token consumption {'prompt_tokens': 1000, 'completion_tokens': 0, 'total_tokens': 1000, 'images': 1}\n",
      "2025-01-09 14:51:24,738 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_0: Found 1 figures in Chunky_Knit_Oversized_Sweater.pdf\n",
      "2025-01-09 14:51:25,075 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_0: Finished reading Chunky_Knit_Oversized_Sweater.pdf in 11.85 seconds\n",
      "2025-01-09 14:51:25,075 - asynch_indexer.AsynchronousIndexer - INFO - Reader read_worker_0: Done processing Chunky_Knit_Oversized_Sweater.pdf\n",
      "2025-01-09 14:51:25,075 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Embedding chunk 3e51c89b-f035-4948-8a43-9433c8b8375b from document Classic_Denim_Jacket.pdf page 1\n",
      "2025-01-09 14:51:25,989 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Finished embedding in 0.91 seconds\n",
      "2025-01-09 14:51:25,989 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Embedding chunk 1697f2a8-e7a9-49eb-91f9-76c5e7859e6d from document Classic_Denim_Jacket.pdf page 2\n",
      "2025-01-09 14:51:26,260 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Finished embedding in 0.27 seconds\n",
      "2025-01-09 14:51:26,260 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Embedding chunk e5903ac8-105b-4585-a248-44b3c4a6ea47 from document Relaxed_Fit Linen_Pants.pdf page 1\n",
      "2025-01-09 14:51:26,507 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Finished embedding in 0.25 seconds\n",
      "2025-01-09 14:51:26,508 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Embedding chunk b86fd5fb-0a50-43ef-ac71-e8bc7cf4fb34 from document Relaxed_Fit Linen_Pants.pdf page 2\n",
      "2025-01-09 14:51:26,723 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Finished embedding in 0.21 seconds\n",
      "2025-01-09 14:51:26,723 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Uploading chunk 7a413492-7220-4dbd-9dc1-c54fa080e0fe of document a4cdd458-b5e8-47df-8963-4b597fa625f4\n",
      "2025-01-09 14:51:26,723 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Successfully uploaded 7a413492-7220-4dbd-9dc1-c54fa080e0fe\n",
      "2025-01-09 14:51:26,738 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Uploading chunk d77cfeef-9d20-4705-bdd1-cdea59f31060 of document 431123df-cae2-41e8-a993-da4bd32da607\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Successfully uploaded d77cfeef-9d20-4705-bdd1-cdea59f31060\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Uploading chunk 3e51c89b-f035-4948-8a43-9433c8b8375b of document a4cdd458-b5e8-47df-8963-4b597fa625f4\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Successfully uploaded 3e51c89b-f035-4948-8a43-9433c8b8375b\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Uploading chunk 1697f2a8-e7a9-49eb-91f9-76c5e7859e6d of document a4cdd458-b5e8-47df-8963-4b597fa625f4\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Successfully uploaded 1697f2a8-e7a9-49eb-91f9-76c5e7859e6d\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Uploading chunk e5903ac8-105b-4585-a248-44b3c4a6ea47 of document 431123df-cae2-41e8-a993-da4bd32da607\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Successfully uploaded e5903ac8-105b-4585-a248-44b3c4a6ea47\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Uploading chunk b86fd5fb-0a50-43ef-ac71-e8bc7cf4fb34 of document 431123df-cae2-41e8-a993-da4bd32da607\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Successfully uploaded b86fd5fb-0a50-43ef-ac71-e8bc7cf4fb34\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Chunking document Chunky_Knit_Oversized_Sweater.pdf page 1\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Finished chunking in 0.00 seconds\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Chunking document Chunky_Knit_Oversized_Sweater.pdf page 2\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - Chunker chunk_worker_0: Finished chunking in 0.00 seconds\n",
      "2025-01-09 14:51:26,739 - asynch_indexer.AsynchronousIndexer - INFO - ImageEmbedder image_embedder_2:Embedding image 77841dd4-16df-4605-b193-d574b9f5b5fc from document Chunky_Knit_Oversized_Sweater.pdf page 1\n",
      "2025-01-09 14:51:29,823 - asynch_indexer.AsynchronousIndexer - INFO - ImageEmbedder image_embedder_2: Successfully processed image 77841dd4-16df-4605-b193-d574b9f5b5fc using model embed-multilingual-v3.0-image. Token consumption {'prompt_tokens': 1000, 'completion_tokens': 0, 'total_tokens': 1000, 'images': 1}\n",
      "2025-01-09 14:51:29,823 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_2: Uploading chunk 77841dd4-16df-4605-b193-d574b9f5b5fc of document 180591d6-92bb-4971-abc4-e2cbe8209413\n",
      "2025-01-09 14:51:29,823 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_2: Successfully uploaded 77841dd4-16df-4605-b193-d574b9f5b5fc\n",
      "2025-01-09 14:51:29,823 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Embedding chunk ce895b3c-e201-43a4-b9aa-80aee83d0079 from document Chunky_Knit_Oversized_Sweater.pdf page 1\n",
      "2025-01-09 14:51:30,090 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Finished embedding in 0.27 seconds\n",
      "2025-01-09 14:51:30,105 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Embedding chunk 502054f0-e7ab-42f1-8825-aa927f18f173 from document Chunky_Knit_Oversized_Sweater.pdf page 2\n",
      "2025-01-09 14:51:30,369 - asynch_indexer.AsynchronousIndexer - INFO - TextEmbedder text_embedder_0: Finished embedding in 0.26 seconds\n",
      "2025-01-09 14:51:30,370 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Uploading chunk ce895b3c-e201-43a4-b9aa-80aee83d0079 of document 180591d6-92bb-4971-abc4-e2cbe8209413\n",
      "2025-01-09 14:51:30,371 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Successfully uploaded ce895b3c-e201-43a4-b9aa-80aee83d0079\n",
      "2025-01-09 14:51:30,371 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Uploading chunk 502054f0-e7ab-42f1-8825-aa927f18f173 of document 180591d6-92bb-4971-abc4-e2cbe8209413\n",
      "2025-01-09 14:51:30,371 - asynch_indexer.AsynchronousIndexer - INFO - Uploader uploader_0: Successfully uploaded 502054f0-e7ab-42f1-8825-aa927f18f173\n",
      "2025-01-09 14:51:30,510 - asynch_indexer.AsynchronousIndexer - INFO - Total indexing time: 20.73 seconds\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio  \n",
    "import asyncio  \n",
    "from asynch_indexer.AsynchronousIndexer import AsynchronousIndexer  \n",
    "   \n",
    "# Necessary when running asyncio in Jupyter notebooks  \n",
    "nest_asyncio.apply()  \n",
    "   \n",
    "# Initialize the AsynchronousIndexer  \n",
    "indexer = AsynchronousIndexer(  \n",
    "    index_name=index_name,  \n",
    "    search_endpoint=search_service_endpoint,  \n",
    "    search_api_key=search_api_key,  \n",
    "    storage_account_name=storage_account_name,  \n",
    "    storage_container_name=storage_container_name,  \n",
    "    ai_foundry_endpoint = ai_foundry_endpoint  ,\n",
    "    ai_foundry_key = ai_foundry_key,\n",
    "    text_embedding_model= text_embedding_model,\n",
    "    image_embedding_model=image_embedding_model, \n",
    "    document_intelligence_endpoint=document_intelligence_endpoint,  \n",
    "    document_intelligence_key=document_intelligence_key,  \n",
    ")  \n",
    "   \n",
    "# Run the indexing pipeline  \n",
    "asyncio.run(indexer.run_indexing())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform Test Searches  \n",
    "    \n",
    "Finally, we'll perform test searches against the index to verify that both the text and image vectors have been indexed correctly. We'll demonstrate how to:\n",
    "\n",
    "1. Perform a text-over-text search, filtering results to only text content.\n",
    "2. Perform an image-over-image search, retrieving image-related results.\n",
    "3. Perform a text-over-image and text search, combining both content types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Setup: Initialize Clients \n",
    "First, we'll initialize the necessary clients for Azure AI Search and Azure AI Foundry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.ai.inference import EmbeddingsClient\n",
    "from azure.ai.inference import ImageEmbeddingsClient  \n",
    "from azure.ai.inference.models import EmbeddingInput   \n",
    "from azure.search.documents.models import VectorizedQuery   \n",
    "   \n",
    "# Initialize the SearchClient  \n",
    "search_client = SearchClient(  \n",
    "    endpoint=search_service_endpoint,  \n",
    "    index_name=index_name,  \n",
    "    credential=AzureKeyCredential(search_api_key),  \n",
    ")\n",
    "\n",
    "# Initialize the EmbeddingsClient for text embeddings  \n",
    "text_embeddings_client = EmbeddingsClient(  \n",
    "    endpoint=ai_foundry_endpoint,  \n",
    "    credential=AzureKeyCredential(ai_foundry_key),  \n",
    "    model=text_embedding_model  \n",
    ")  \n",
    "\n",
    "# Initialize the EmbeddingsClient for image embeddings  \n",
    "image_embeddings_client = ImageEmbeddingsClient(  \n",
    "    endpoint=ai_foundry_endpoint,  \n",
    "    credential=AzureKeyCredential(ai_foundry_key),  \n",
    "    model=image_embedding_model  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Helper Functions\n",
    " \n",
    "We'll define helper functions to generate embeddings for text and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64  \n",
    "from PIL import Image  \n",
    "import io  \n",
    "  \n",
    "def get_text_embedding(query):  \n",
    "    response = text_embeddings_client.embed(  \n",
    "        input=[query]  \n",
    "    )  \n",
    "    print(\"Text Embedding Model:\", response.model)  \n",
    "    print(\"Usage:\", response.usage)  \n",
    "    return response.data[0].embedding  \n",
    "  \n",
    "def get_image_embedding(image_path):  \n",
    "    # Open the image file  \n",
    "    with open(image_path, \"rb\") as image_file:  \n",
    "        image_data = image_file.read()  \n",
    "    # Convert image data to base64 data URL  \n",
    "    image_base64 = base64.b64encode(image_data).decode('utf-8')  \n",
    "    data_url = f\"data:image/png;base64,{image_base64}\"  \n",
    "    response = image_embeddings_client.embed(  \n",
    "        input=[EmbeddingInput(image=data_url)]  \n",
    "    )  \n",
    "    print(\"Image Embedding Model:\", response.model)  \n",
    "    print(\"Usage:\", response.usage)  \n",
    "    return response.data[0].embedding  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Text-over-Text Search\n",
    " \n",
    "In this section, we'll perform a search where we input a text query and retrieve text content from the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding Model: embed-multilingual-v3.0\n",
      "Usage: {'prompt_tokens': 2, 'completion_tokens': 0, 'total_tokens': 2}\n",
      "Title: Classic_Denim_Jacket.pdf\n",
      "Page Number: 2\n",
      "Content Type: text\n",
      "Chunk: modern unisex fit, and a versatile design suitable for all seasons. With two front chest pockets,\n",
      "button closures, and subtle distressing, it's a perfect blend of casual and chic.\n",
      "How to Use:\n",
      "· Pair it with a plain white t-shirt and black jeans for a classic, everyday outfit.\n",
      "· Layer it over a hoodie for a relaxed streetwear aesthetic on cooler days.\n",
      ". Wear it over a summer dress or shorts for a laid-back, trendy look during warmer\n",
      "months.\n",
      "Key Features:\n",
      "· Fabric: 100% Cotton Denim\n",
      "· Fit: Regular Unisex Fit\n",
      "· Button closures and adjustable cuffs\n",
      "· Machine washable for easy care\n",
      "· Available in sizes XS to XXL\n",
      "source_link: https://demosharedstorage1.blob.core.windows.net/products-demo/Classic_Denim_Jacket.pdf\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Define the search query  \n",
    "query_text = \"wedding dress\"  \n",
    "   \n",
    "# Get the query embedding  \n",
    "query_embedding = get_text_embedding(query_text) \n",
    "   \n",
    "# Define the vector query  \n",
    "vector_query = VectorizedQuery(  \n",
    "    vector=query_embedding,  \n",
    "    k_nearest_neighbors=3,  \n",
    "    fields=\"text_vector\", \n",
    ")  \n",
    "   \n",
    "# Perform the search with a filter on content_type  \n",
    "results = search_client.search(  \n",
    "    search_text=query_embedding,  # Leave empty if you want to use only vector search.\n",
    "    vector_queries=[vector_query],  \n",
    "    filter=\"content_type eq 'text'\", #Since we're only interested in text content, we filtered the results to where content_type is 'text'.\n",
    "    select=[\"title\", \"chunk\", \"page_number\", \"source_link\", \"content_type\"],   \n",
    "    top=1  \n",
    ")  \n",
    "   \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Page Number: {result['page_number']}\")  \n",
    "    print(f\"Content Type: {result['content_type']}\")  \n",
    "    print(f\"Chunk: {result['chunk']}\")  \n",
    "    print(f\"source_link: {result['source_link']}\")  \n",
    "    print(\"---\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Image-over-Image Search\n",
    " \n",
    "Next, we'll perform a search where we input an image query and retrieve image content from the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Embedding Model: embed-multilingual-v3.0-image\n",
      "Usage: {'prompt_tokens': 1000, 'completion_tokens': 0, 'total_tokens': 1000, 'images': 1}\n",
      "Image-over-Image Search Results:\n",
      "Title: Classic_Denim_Jacket.pdf\n",
      "Page Number: 1\n",
      "Content Type: image\n",
      "Blob URI: https://demosharedstorage1.blob.core.windows.net/products-demo/Classic_Denim_Jacket.pdf\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Provide the path to your query image  \n",
    "image_query_path = \"./sample_Data/test_image.png\"\n",
    "\n",
    "# Get the image embedding  \n",
    "image_query_embedding = get_image_embedding(image_query_path) \n",
    "\n",
    "# Define the vector query  \n",
    "vector_query = VectorizedQuery(  \n",
    "    vector=image_query_embedding,  \n",
    "    k_nearest_neighbors=5,  \n",
    "    fields=\"image_vector\",  \n",
    ")  \n",
    "\n",
    "# Perform the search with a filter on content_type  \n",
    "results = search_client.search(  \n",
    "    search_text=\"\",  \n",
    "    vector_queries=[vector_query],  \n",
    "    filter=\"content_type eq 'image'\",  \n",
    "    select=[\"title\", \"page_number\", \"source_link\", \"content_type\"],  \n",
    "    top=1  \n",
    ")\n",
    "\n",
    "# Print the results  \n",
    "print(\"Image-over-Image Search Results:\")  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Page Number: {result['page_number']}\")  \n",
    "    print(f\"Content Type: {result['content_type']}\")  \n",
    "    print(f\"Blob URI: {result['source_link']}\")  \n",
    "    print(\"---\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Text-over-Image and Text Search\n",
    " \n",
    "Finally, we'll perform a search where we input a text query and retrieve both text and image content from the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding Model: embed-multilingual-v3.0\n",
      "Usage: {'prompt_tokens': 2, 'completion_tokens': 0, 'total_tokens': 2}\n",
      "Title: Relaxed_Fit Linen_Pants.pdf\n",
      "Page Number: 2\n",
      "Content Type: text\n",
      "source_link: https://demosharedstorage1.blob.core.windows.net/products-demo/Relaxed_Fit%20Linen_Pants.pdf\n",
      "---\n",
      "Title: Classic_Denim_Jacket.pdf\n",
      "Page Number: 1\n",
      "Content Type: image\n",
      "source_link: https://demosharedstorage1.blob.core.windows.net/products-demo/Classic_Denim_Jacket.pdf\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Define the search query  \n",
    "query_text = \"wedding dress\"  \n",
    "\n",
    "# Get the query embedding  \n",
    "query_embedding = get_text_embedding(query_text)  \n",
    "\n",
    "# Define vector queries for both text and image vectors  \n",
    "text_vector_query = VectorizedQuery(  \n",
    "    vector=query_embedding,  \n",
    "    k_nearest_neighbors=5,  \n",
    "    fields=\"text_vector\",  \n",
    ")  \n",
    "  \n",
    "image_vector_query = VectorizedQuery(  \n",
    "    vector=query_embedding,  \n",
    "    k_nearest_neighbors=5,  \n",
    "    fields=\"image_vector\",  \n",
    ")  \n",
    "  \n",
    "# Perform the searches separately  \n",
    "text_results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries=[text_vector_query],  \n",
    "    select=[\"title\", \"chunk\", \"page_number\", \"source_link\", \"content_type\"],  \n",
    "    top=1 \n",
    ")  \n",
    "  \n",
    "image_results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries=[image_vector_query],  \n",
    "    select=[\"title\", \"page_number\", \"source_link\", \"content_type\"],  \n",
    "    top=1  \n",
    ")  \n",
    "\n",
    "# Display the results  \n",
    "for result in text_results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Page Number: {result['page_number']}\")  \n",
    "    print(f\"Content Type: {result['content_type']}\")   \n",
    "    print(f\"source_link: {result['source_link']}\")  \n",
    "    print(\"---\") \n",
    "\n",
    "\n",
    "# Display the combined results  \n",
    "for result in image_results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Page Number: {result['page_number']}\")  \n",
    "    print(f\"Content Type: {result['content_type']}\")   \n",
    "    print(f\"source_link: {result['source_link']}\")  \n",
    "    print(\"---\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "   \n",
    "In this notebook, we've built a custom asynchronous indexing pipeline that processes both text and images from PDF documents, generates embeddings using Azure OpenAI and Azure AI Inference, and indexes them into Azure Cognitive Search. This allows for advanced vector-based searches over both text and images.  \n",
    "   \n",
    "You can extend this pipeline to handle more complex scenarios, larger datasets, or integrate additional processing steps as needed.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
