{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting Data Using Azure AI Search Indexer (Pull Method)  \n",
    "   \n",
    "This notebook demonstrates how to ingest data into Azure AI Search using the indexer (pull method). We'll set up a data source, create an index, define a skillset for data enrichment, configure an indexer, and perform a search query to retrieve results.  \n",
    "   \n",
    "## Prerequisites  \n",
    "   \n",
    "- **Azure Subscription** with access to:  \n",
    "  - Azure AI Search service  \n",
    "  - Azure Storage account (Blob storage)  \n",
    "  - Azure OpenAI service  \n",
    "  - Azure AI Services  \n",
    "- **Environment variables** set in a `.env` file or environment variables:  \n",
    "  - `AZURE_SEARCH_SERVICE_ENDPOINT`  \n",
    "  - `AZURE_SEARCH_API_KEY`  \n",
    "  - `AZURE_STORAGE_ACCOUNT_SUB_ID`  \n",
    "  - `AZURE_STORAGE_ACCOUNT_RG_NAME`  \n",
    "  - `AZURE_STORAGE_ACCOUNT_NAME`  \n",
    "  - `AZURE_OPENAI_ENDPOINT`  \n",
    "  - `AZURE_OPENAI_KEY`  \n",
    "  - `AZURE_OPENAI_EMBEDDING_DEPLOYMENT`  \n",
    "  - `AZURE_OPENAI_EMBEDDING_MODEL_NAME`  \n",
    "  - `AZURE_AI_SERVICES_ENDPOINT`  \n",
    "  - `AZURE_AI_SERVICES_KEY`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Set Up Environment Variables and Credentials  \n",
    "   \n",
    "Import necessary libraries and load environment variables required for authentication and configuration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1719927585629
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries  \n",
    "from dotenv import load_dotenv  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "import os  \n",
    "  \n",
    "# Load environment variables from a .env file  \n",
    "load_dotenv(override=True)  # Take environment variables from .env.  \n",
    "  \n",
    "# Azure Cognitive Search credentials  \n",
    "search_service_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]  \n",
    "search_api_key = AzureKeyCredential(os.environ[\"AZURE_SEARCH_API_KEY\"])  \n",
    "index_name = \"indexer-demo\"  \n",
    "  \n",
    "# Azure Storage account details  \n",
    "storage_subscription_id = os.environ[\"AZURE_STORAGE_ACCOUNT_SUB_ID\"]  \n",
    "storage_resource_group = os.environ[\"AZURE_STORAGE_ACCOUNT_RG_NAME\"]  \n",
    "storage_account_name = os.environ[\"AZURE_STORAGE_ACCOUNT_NAME\"]  \n",
    "  \n",
    "# Construct the data source connection string for the storage account  \n",
    "storage_connection_string = (  \n",
    "    f\"ResourceId=/subscriptions/{storage_subscription_id}\"  \n",
    "    f\"/resourceGroups/{storage_resource_group}\"  \n",
    "    f\"/providers/Microsoft.Storage/storageAccounts/{storage_account_name}/;\"  \n",
    ")  \n",
    "  \n",
    "# Azure OpenAI service credentials  \n",
    "openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]  \n",
    "openai_api_key = os.environ[\"AZURE_OPENAI_KEY\"]  \n",
    "openai_embedding_deployment = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"]  \n",
    "openai_model_name = os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\"]  \n",
    "openai_model_dimensions = int(  \n",
    "    os.getenv(\"AZURE_OPENAI_EMBEDDING_DIMENSIONS\", 1536)  # Default to 1536 dimensions  \n",
    ")  \n",
    "  \n",
    "# Azure AI Services credentials  \n",
    "ai_services_endpoint = os.environ[\"AZURE_AI_SERVICES_ENDPOINT\"]  \n",
    "ai_services_api_key = os.environ[\"AZURE_AI_SERVICES_KEY\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Section 2: Create a Blob Data Source Connector on Azure AI Search  \n",
    "   \n",
    "Set up a data source connection to your Azure Blob Storage, which the indexer will use to pull data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1720090061592
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source 'indexer-demo-blob' created or updated.\n",
      "Please ensure your Azure AI Search service has the 'Storage Blob Data Reader' role assigned on the storage account to access blob data.\n"
     ]
    }
   ],
   "source": [
    "# Import required classes for the indexer client  \n",
    "from azure.search.documents.indexes import SearchIndexerClient  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndexerDataContainer,  \n",
    "    SearchIndexerDataSourceConnection  \n",
    ")  \n",
    "  \n",
    "# Create the indexer client  \n",
    "indexer_client = SearchIndexerClient(  \n",
    "    endpoint=search_service_endpoint,  \n",
    "    credential=search_api_key  \n",
    ")  \n",
    "  \n",
    "# Define the data source connection  \n",
    "data_source_name = f\"{index_name}-blob\"  \n",
    "data_container_name = \"demo-indexer-storage\"  # Replace with your blob container name  \n",
    "data_source = SearchIndexerDataSourceConnection(  \n",
    "    name=data_source_name,  \n",
    "    type=\"azureblob\",  \n",
    "    connection_string=storage_connection_string,  \n",
    "    container=SearchIndexerDataContainer(name=data_container_name)  \n",
    ")  \n",
    "  \n",
    "# Create or update the data source connection  \n",
    "indexer_client.create_or_update_data_source_connection(data_source)  \n",
    "print(f\"Data source '{data_source.name}' created or updated.\")  \n",
    "  \n",
    "# Reminder to set permissions  \n",
    "print(  \n",
    "    \"Please ensure your Azure AI Search service has the 'Storage Blob Data Reader' role \"  \n",
    "    \"assigned on the storage account to access blob data.\"  \n",
    ")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Section 3: Create a Search Index  \n",
    "   \n",
    "Define the index schema, including fields and configurations for vector and semantic search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1720090065953
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'indexer-demo' created or updated.\n"
     ]
    }
   ],
   "source": [
    "# Import required classes for creating the search index  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    VectorSearch,  \n",
    "    HnswAlgorithmConfiguration,  \n",
    "    VectorSearchProfile,  \n",
    "    AzureOpenAIVectorizer,  \n",
    "    AzureOpenAIParameters,  \n",
    "    AIServicesVisionVectorizer,  \n",
    "    AIServicesVisionParameters,  \n",
    "    SemanticConfiguration,  \n",
    "    SemanticSearch,  \n",
    "    SemanticPrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchIndex  \n",
    ")  \n",
    "  \n",
    "# Create a search index client  \n",
    "search_index_client = SearchIndexClient(  \n",
    "    endpoint=search_service_endpoint,  \n",
    "    credential=search_api_key  \n",
    ")  \n",
    "  \n",
    "# Define the index schema fields  \n",
    "fields = [  \n",
    "    # Field for parent ID of text documents  \n",
    "    SearchField(  \n",
    "        name=\"text_parent_id\",  \n",
    "        type=SearchFieldDataType.String,  \n",
    "        sortable=True,  \n",
    "        filterable=True,  \n",
    "        facetable=True  \n",
    "    ),  \n",
    "    # Field for parent ID of image documents  \n",
    "    SearchField(  \n",
    "        name=\"image_parent_id\",  \n",
    "        type=SearchFieldDataType.String,  \n",
    "        sortable=True,  \n",
    "        filterable=True,  \n",
    "        facetable=True  \n",
    "    ),  \n",
    "    # Field for document title  \n",
    "    SearchField(  \n",
    "        name=\"title\",  \n",
    "        type=SearchFieldDataType.String  \n",
    "    ),  \n",
    "    # Field for chunk ID, used as the key  \n",
    "    SearchField(  \n",
    "        name=\"chunk_id\",  \n",
    "        type=SearchFieldDataType.String,  \n",
    "        key=True,  \n",
    "        sortable=True,  \n",
    "        filterable=True,  \n",
    "        facetable=True,  \n",
    "        analyzer_name=\"keyword\"  \n",
    "    ),  \n",
    "    # Field for text chunks  \n",
    "    SearchField(  \n",
    "        name=\"chunk\",  \n",
    "        type=SearchFieldDataType.String,  \n",
    "        sortable=False,  \n",
    "        filterable=False,  \n",
    "        facetable=False  \n",
    "    ),  \n",
    "    # Field for text embeddings (vector)  \n",
    "    SearchField(  \n",
    "        name=\"text_vector\",  \n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  \n",
    "        vector_search_dimensions=openai_model_dimensions,  \n",
    "        vector_search_profile_name=\"textVectorSearchProfile\"  \n",
    "    ),  \n",
    "    # Field for image embeddings (vector)  \n",
    "    SearchField(  \n",
    "        name=\"image_vector\",  \n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  \n",
    "        vector_search_dimensions=1024,  \n",
    "        vector_search_profile_name=\"imageVectorSearchProfile\"  \n",
    "    ),  \n",
    "]  \n",
    "  \n",
    "# Configure vector search settings  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"hnswAlgorithm\"),  # HNSW algorithm for approximate nearest neighbor search  \n",
    "    ],  \n",
    "    profiles=[  \n",
    "        # Profile for text vector search using Azure OpenAI  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"textVectorSearchProfile\",  \n",
    "            algorithm_configuration_name=\"hnswAlgorithm\",  \n",
    "            vectorizer=\"AzureOpenAIVectorizer\"  \n",
    "        ),  \n",
    "        # Profile for image vector search using AI Services Vision  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"imageVectorSearchProfile\",  \n",
    "            algorithm_configuration_name=\"hnswAlgorithm\",  \n",
    "            vectorizer=\"AIServicesVisionVectorizer\"  \n",
    "        ),  \n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        # Vectorizer for AI Services Vision (images)  \n",
    "        AIServicesVisionVectorizer(  \n",
    "            name=\"AIServicesVisionVectorizer\",  \n",
    "            kind=\"aiServicesVision\",  \n",
    "            ai_services_vision_parameters=AIServicesVisionParameters(  \n",
    "                model_version=\"2023-04-15\",  \n",
    "                resource_uri=ai_services_endpoint,  \n",
    "                api_key=ai_services_api_key,  \n",
    "            )  \n",
    "        ),  \n",
    "        # Vectorizer for Azure OpenAI (text)  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"AzureOpenAIVectorizer\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=openai_endpoint,  \n",
    "                deployment_id=openai_embedding_deployment,  \n",
    "                model_name=openai_model_name,  \n",
    "                api_key=openai_api_key,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "# Configure semantic search settings  \n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(  \n",
    "        title_field=SemanticField(field_name=\"title\"),  \n",
    "        content_fields=[SemanticField(field_name=\"chunk\")]  \n",
    "    )  \n",
    ")  \n",
    "  \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index with the defined schema and configurations  \n",
    "index = SearchIndex(  \n",
    "    name=index_name,  \n",
    "    fields=fields,  \n",
    "    vector_search=vector_search,  \n",
    "    semantic_search=semantic_search  \n",
    ")  \n",
    "  \n",
    "# Create or update the index in Azure Cognitive Search  \n",
    "search_index_client.create_or_update_index(index)  \n",
    "print(f\"Index '{index.name}' created or updated.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Section 4: Create a Skillset  \n",
    "   \n",
    "Define a skillset for data enrichment, including skills for splitting documents, generating embeddings, and processing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1720090070844
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skillset 'indexer-demo-skillset' created or updated.\n"
     ]
    }
   ],
   "source": [
    "# Import required classes for creating the skillset  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SplitSkill,  \n",
    "    InputFieldMappingEntry,  \n",
    "    OutputFieldMappingEntry,  \n",
    "    AzureOpenAIEmbeddingSkill,  \n",
    "    VisionVectorizeSkill,  \n",
    "    SearchIndexerIndexProjections,  \n",
    "    SearchIndexerIndexProjectionSelector,  \n",
    "    SearchIndexerIndexProjectionsParameters,  \n",
    "    IndexProjectionMode,  \n",
    "    SearchIndexerSkillset,  \n",
    "    CognitiveServicesAccountKey  \n",
    ")  \n",
    "  \n",
    "# Define the SplitSkill to split documents into smaller chunks (pages)  \n",
    "split_skill = SplitSkill(  \n",
    "    name=\"SplitSkill\",  \n",
    "    description=\"Split documents into pages for chunking\",  \n",
    "    context=\"/document\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    maximum_page_length=2000,  \n",
    "    page_overlap_length=500,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "# Define the VisionVectorizeSkill for image processing  \n",
    "vision_vectorize_skill = VisionVectorizeSkill(  \n",
    "    name=\"VisionVectorizeSkill\",  \n",
    "    description=\"Generate vector representations of images\",  \n",
    "    context=\"/document/normalized_images/*\",  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"image\", source=\"/document/normalized_images/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"vector\", target_name=\"image_vector\")  \n",
    "    ],  \n",
    "    model_version=\"2023-04-15\"  \n",
    ")  \n",
    "  \n",
    "# Define the AzureOpenAIEmbeddingSkill for text embeddings  \n",
    "openai_embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    name=\"AzureOpenAIEmbeddingSkill\",  \n",
    "    description=\"Generate text embeddings using Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",  \n",
    "    resource_uri=openai_endpoint,  \n",
    "    deployment_id=openai_embedding_deployment,  \n",
    "    model_name=openai_model_name,  \n",
    "    dimensions=openai_model_dimensions,  \n",
    "    api_key=openai_api_key,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "# Define index projections to map the output of the skillset to the search index  \n",
    "index_projections = SearchIndexerIndexProjections(  \n",
    "    selectors=[  \n",
    "        # Selector for text documents  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"text_parent_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(  \n",
    "                    name=\"chunk\",  \n",
    "                    source=\"/document/pages/*\"  \n",
    "                ),  \n",
    "                InputFieldMappingEntry(  \n",
    "                    name=\"text_vector\",  \n",
    "                    source=\"/document/pages/*/text_vector\"  \n",
    "                ),  \n",
    "                InputFieldMappingEntry(  \n",
    "                    name=\"title\",  \n",
    "                    source=\"/document/metadata_storage_name\"  \n",
    "                ),  \n",
    "            ],  \n",
    "        ),  \n",
    "        # Selector for image documents  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"image_parent_id\",  \n",
    "            source_context=\"/document/normalized_images/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(  \n",
    "                    name=\"image_vector\",  \n",
    "                    source=\"/document/normalized_images/*/image_vector\"  \n",
    "                ),  \n",
    "            ],  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "# Combine all skills into a skillset  \n",
    "skills = [split_skill, openai_embedding_skill, vision_vectorize_skill]  \n",
    "  \n",
    "skillset_name = f\"{index_name}-skillset\"  \n",
    "  \n",
    "# Define the cognitive services account for AI enrichment  \n",
    "cognitive_services_account = CognitiveServicesAccountKey(  \n",
    "    key=ai_services_api_key,  \n",
    "    description=\"Azure Cognitive Services account key for AI enrichment\",  \n",
    ")  \n",
    "  \n",
    "# Create the skillset  \n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset for chunking documents and generating embeddings\",  \n",
    "    skills=skills,  \n",
    "    index_projections=index_projections,  \n",
    "    cognitive_services_account=cognitive_services_account,  \n",
    ")  \n",
    "  \n",
    "# Create or update the skillset in Azure Cognitive Search  \n",
    "indexer_client.create_or_update_skillset(skillset)  \n",
    "print(f\"Skillset '{skillset.name}' created or updated.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Create and Run the Indexer  \n",
    "   \n",
    "Configure and run the indexer to process data from the data source, apply the skillset, and index the documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1720090088040
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexer 'indexer-demo-indexer' created and running.\n"
     ]
    }
   ],
   "source": [
    "# Import required classes for creating the indexer  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndexer,  \n",
    "    FieldMapping,  \n",
    "    IndexingParameters,  \n",
    "    IndexingParametersConfiguration,  \n",
    ")  \n",
    "  \n",
    "# Define the indexer name  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "  \n",
    "# Configure indexing parameters  \n",
    "indexing_parameters = IndexingParameters(  \n",
    "    configuration=IndexingParametersConfiguration(  \n",
    "        image_action=\"generateNormalizedImages\",  # Generate normalized images for processing  \n",
    "        query_timeout=None,  \n",
    "        data_to_extract=\"contentAndMetadata\",  \n",
    "    )  \n",
    ")  \n",
    "  \n",
    "# Create the indexer  \n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to process documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,  \n",
    "    # Map the metadata_storage_name field to the title field in the index  \n",
    "    field_mappings=[  \n",
    "        FieldMapping(  \n",
    "            source_field_name=\"metadata_storage_name\",  \n",
    "            target_field_name=\"title\"  \n",
    "        )  \n",
    "    ],  \n",
    "    parameters=indexing_parameters,  \n",
    ")  \n",
    "  \n",
    "# Create or update the indexer in Azure Cognitive Search  \n",
    "indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer to start indexing data  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f\"Indexer '{indexer_name}' created and running.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Perform a Search and Display Results  \n",
    "   \n",
    "Use the search client to query the indexed data and display the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: Margie’s Travel Presents… \n",
      "\n",
      "London \n",
      "London is the capital and \n",
      "\n",
      "most populous city of \n",
      "\n",
      "England and the United \n",
      "\n",
      "Kingdom. Standing on the \n",
      "\n",
      "River Thames in the south \n",
      "\n",
      "east of the island of Great \n",
      "\n",
      "Britain, London has been \n",
      "\n",
      "a major settlement for two \n",
      "\n",
      "millennia. It was founded \n",
      "\n",
      "by the Romans, who \n",
      "\n",
      "named it Londinium. \n",
      "\n",
      "London's ancient core, the \n",
      "\n",
      "City of London, largely \n",
      "\n",
      "retains its 1.12-square- \n",
      "\n",
      "mile medieval boundaries. \n",
      "\n",
      "Since at least the 19th century, London has also referred to the metropolis around this core, \n",
      "\n",
      "historically split between Middlesex, Essex, Surrey, Kent, and Hertfordshire, which today largely \n",
      "\n",
      "makes up Greater London, governed by the Mayor of London and the London Assembly. \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "Mostly popular for: \n",
      "Leisure, Outdoors, Historical, Arts \n",
      "& Culture \n",
      "\n",
      "Best time to visit: \n",
      "Jun-Aug \n",
      "Averag Precipitation: 1.9 in \n",
      "Average Temperature: 56-67°F \n",
      "\n",
      " \n",
      " \n",
      " \n",
      "\n",
      " \n",
      "\n",
      "London Hotels \n",
      "\n",
      "Margie’s Travel offers the following accommodation options in London: \n",
      "\n",
      "The Buckingham Hotel \n",
      "\n",
      "Comfortable hotel close to major sights like Buckingham Palace, Regent’s Park, and Trafalgar \n",
      "\n",
      "Square. \n",
      "\n",
      "The City Hotel \n",
      "\n",
      "Luxury rooms in the city, within walking distance of Tower Bridge and the Tower of London.. \n",
      "\n",
      "The Kensington Hotel \n",
      "\n",
      "Budget accommodation near Earl’s Court. \n",
      "\n",
      "To book your trip to London, visit www.margiestravel.com \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "http://www.margiestravel.com/\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Category Information \n",
      "\n",
      "Country United Kingdom \n",
      "\n",
      "Capital Of England \n",
      "\n",
      "Currency Pound Sterling (GBP) \n",
      "\n",
      "Population (2021 census) Approximately 8.8 million \n",
      "\n",
      "Famous For Historical landmarks, museums, cultural diversity\n",
      "\n",
      "Score: 0.03333333507180214\n",
      "\n",
      "Chunk: Infrastructure is forecasted to be one of the fastest-growing \n",
      "segments of private markets\n",
      "\n",
      "4\n",
      "\n",
      "729\n",
      "1,190\n",
      "\n",
      "2,541\n",
      "\n",
      "2017 2022 2027 Energy Telecom \n",
      "& digital\n",
      "\n",
      "Transport Water\n",
      "\n",
      "23\n",
      "\n",
      "7\n",
      "\n",
      "40\n",
      "\n",
      "5\n",
      "\n",
      "Investment\n",
      "\n",
      "Needs\n",
      "\n",
      "2022-2040 cumulative infrastructure investment & needs, $T\n",
      "\n",
      "16% \n",
      "CAGR\n",
      "\n",
      "Note: For footnoted information, refer to slide 11.\n",
      "\n",
      "10% \n",
      "CAGR\n",
      "\n",
      "Industry infrastructure AUM1 $75T global infrastructure funding need2\n",
      "\n",
      "Clients allocating more to infra in new market regime3 Infrastructure fares well in inflationary environments4\n",
      "\n",
      "43%\n",
      "\n",
      "37%\n",
      "\n",
      "28%\n",
      "\n",
      "22%\n",
      "\n",
      "22%\n",
      "\n",
      "18%\n",
      "\n",
      "39%\n",
      "\n",
      "45%\n",
      "\n",
      "57%\n",
      "\n",
      "50%\n",
      "\n",
      "43%\n",
      "\n",
      "52%\n",
      "\n",
      "18%\n",
      "\n",
      "18%\n",
      "\n",
      "15%\n",
      "\n",
      "28%\n",
      "\n",
      "35%\n",
      "\n",
      "30%\n",
      "\n",
      "Private Debt\n",
      "\n",
      "Infrastructure\n",
      "\n",
      "Private Equity\n",
      "\n",
      "Hedge Funds\n",
      "\n",
      "Venture Capital\n",
      "\n",
      "Real Estate\n",
      "\n",
      "More capital Same amount of capital Less capital\n",
      "\n",
      "Global Direct \n",
      "Infrastructure\n",
      "\n",
      "Global Direct \n",
      "Real Estate\n",
      "\n",
      "Global Equities Global Fixed \n",
      "Income\n",
      "\n",
      "17% 16% 15%\n",
      "\n",
      "0%\n",
      "\n",
      "Global Direct \n",
      "Infrastructure\n",
      "\n",
      "Global Direct \n",
      "Real Estate\n",
      "\n",
      "Global Equities Global Fixed \n",
      "Income\n",
      "\n",
      "23%\n",
      "\n",
      "8%\n",
      "2%\n",
      "\n",
      "8%\n",
      "\n",
      "High growth / high inflation\n",
      "\n",
      "Low growth / high inflation\n",
      "\n",
      "2\n",
      "0\n",
      "\n",
      "-y\n",
      "ea\n",
      "\n",
      "r t\n",
      "ot\n",
      "\n",
      "al\n",
      " r\n",
      "\n",
      "et\n",
      "u\n",
      "\n",
      "rn\n",
      "s \n",
      "\n",
      "(a\n",
      "n\n",
      "\n",
      "n\n",
      "’d\n",
      "\n",
      ")\n",
      "\n",
      "Score: 0.016393441706895828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary classes for searching  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.models import VectorizableTextQuery  \n",
    "  \n",
    "# Initialize the SearchClient  \n",
    "search_client = SearchClient(  \n",
    "    endpoint=search_service_endpoint,  \n",
    "    index_name=index_name,  \n",
    "    credential=search_api_key,  \n",
    ")  \n",
    "  \n",
    "# Define the search query  \n",
    "query_text = \"London\"  # Query text  \n",
    "  \n",
    "# Create a vectorizable text query for semantic search  \n",
    "vector_query = VectorizableTextQuery(  \n",
    "    text=query_text,  \n",
    "    k_nearest_neighbors=3,  \n",
    "    fields=\"text_vector\",  # Use the text vector field for vector search  \n",
    ")  \n",
    "  \n",
    "# Perform the search  \n",
    "results = search_client.search(  \n",
    "    search_text=query_text,  \n",
    "    vector_queries=[vector_query],  \n",
    "    top=3  # Retrieve the top 3 results  \n",
    ")  \n",
    "  \n",
    "# Print the results  \n",
    "for result in results:  \n",
    "    print(f\"Chunk: {result['chunk']}\\n\")  \n",
    "    print(f\"Score: {result['@search.score']}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
